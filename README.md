# AI-AAT  
## ğŸ… Tomato Leaf Disease Detection & Mobile Deployment

AI-AAT is a deep learningâ€“based tomato leaf disease detection system designed with
**cross-domain robustness**, **explainable AI**, and **efficient mobile deployment**
in mind. The project demonstrates an end-to-end pipeline from model training to
offline Android deployment using **Flutter** and **ONNX Runtime**.

---

## ğŸ” Key Features

- Multiclass tomato leaf disease classification  
- Cross-domain evaluation (lab â†’ real-field images)  
- Multi-model comparison (DenseNet121 vs ResNet50)  
- Explainable AI using **Grad-CAM++** and **LIME**  
- ONNX export with **INT8 post-training quantization**  
- Offline Android deployment using **Flutter**  

---

## ğŸ“‚ Dataset

This project uses **publicly available datasets** (not included in this repository):

### ğŸŸ¢ Training Dataset
- **PlantVillage (Tomato subset)**
- Lab-controlled images
- Used for training and validation

### ğŸ”µ Testing Dataset
- **TomatoVillage â€“ Variant A (Multiclass Classification)**
- Real-field images
- Used for cross-domain evaluation

> âš ï¸ Note: The TomatoVillage dataset contains only a subset of disease classes.
> Evaluation is therefore restricted to overlapping categories, following standard
> cross-domain evaluation practice.

---

## ğŸ§  Models

### ğŸ”¹ Primary Model (Deployed)
- **DenseNet121**
- Framework: PyTorch
- Selected due to better accuracy-to-parameter efficiency and stronger
  cross-domain generalization

### ğŸ”¹ Comparative Model
- **ResNet50**
- Used for architectural comparison and ablation analysis

---

## ğŸ§ª Explainable AI (XAI)

Model decisions are interpreted using:

- **Grad-CAM++** â€“ Visualizes spatial attention on diseased regions  
- **LIME** â€“ Highlights superpixel-level feature contributions  

Explainability analysis confirms that the models focus on
**biologically relevant disease patterns**, improving trust and transparency.

---

## âš™ï¸ Optimization & Quantization

- Models exported to **ONNX format**
- **Static INT8 post-training quantization** applied using ONNX Runtime
- Achieved:
  - ~70% reduction in model size
  - Faster on-device inference
  - No retraining required

---

## ğŸš€ Deployment

- **Platform:** Android  
- **Framework:** Flutter  
- **Inference Engine:** ONNX Runtime Mobile  
- **Mode:** Fully offline, on-device inference  

Only the **best-performing DenseNet121 model** is deployed to ensure
lightweight and efficient mobile inference.

---

## ğŸ“Š Experimental Results (Summary)

- Cross-domain accuracy reflects realistic domain shift between lab and field images  
- Late blight shows stronger generalization due to distinctive visual characteristics  
- Explainable AI validates meaningful attention on disease-affected regions  
- INT8 quantization enables practical mobile deployment  

---

## ğŸ“˜ How to Run

1. Open `notebooks/Tomato_Leaf_Disease.ipynb` in **Google Colab**
2. Train models and perform cross-domain evaluation
3. Generate XAI visualizations (Grad-CAM++ & LIME)
4. Export ONNX models and apply INT8 quantization
5. Deploy the model using the Flutter app in `flutter_app/`

---

## ğŸ“ Repository Structure

AI-AAT/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ Tomato_Leaf_Disease.ipynb
â”‚
â”œâ”€â”€ flutter_app/
â”‚ â””â”€â”€ Flutter mobile application
â”‚
â”œâ”€â”€ deployment/
â”‚ â”œâ”€â”€ densenet121_fp32.onnx
â”‚ â””â”€â”€ densenet121_int8.onnx
â”‚
â””â”€â”€ README.md


---

## ğŸ‘¨â€ğŸ“ Author

**Mohammed Sulaiman**  
M.Tech. Computer Science & Engineering  
Interests: Deep Learning, Computer Vision, Explainable AI, Mobile AI Deployment

---

## ğŸ“„ License

This project is intended for **academic and research purposes**.
Please cite the original datasets and libraries used.
